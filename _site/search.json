[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Quarto Website",
    "section": "",
    "text": "Dashboard\nHello! I am a first year masters student in the Social Data Analytics and Research program.\nThis website showcases my work in Knowledge Mining Spring 2026.\nContact Information:\nPhone Number: (972) 832-1806\nWork Number: (972) 883-3743\nEmail: kmg200008@UTdallas.edu"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About me!\nI am a first year masters student in the Social Data Analytics and Research program at the University of Texas at Dallas. I completed my bachelors in Psychology from the University of Texas at Arlington. After graduating, I become a lab manager for the Kennedy and Rodrigue Cognitive Neuroscience lab at UTD.\nI was interested in social data analytics because I wanted to broaden my realm of knowledge. I do not have strong coding or statistical skills, but I know that these skills would better equip me for jobs in psychology and data analysis.\nMy research interests include: The use of psychedelics on treatment resistant depression. I believe that we should expanding the number of modalities available for mental health disorders in order to help as many people as possible.\nSome fun facts about me:\n\nI am left handed\nI have one small Pug-Pomeranian dog\nI am an avid chess and Tetris player\nI enjoy archery, crocheting, and playing video games"
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "assignment1",
    "section": "",
    "text": "Comparing “Statistical Modeling: The Two Cultures” and “To Explain or to Predict?”\nStatistical Modeling: The Two Cultures tackled the issue of data modeling being the primary approach in the science field, but algorithmic models are often more reliable for predictions in larger data sets and handling modern problems. For instance, Breiman discusses problems in data modeling by explaining a residual analysis where a data set is limited to two or three variables. He mentions that a goodness-of-fit test “lacks power in more than a few dimensions.” (203, Breiman) and how an acceptable plot does not mean that it is necessarily a good plot to use for data. He also explains that researchers are not usually looking for if the models they use fit the data, but if the model is new, clever, and sets them apart. Algorithmic models, although simpler, provide a higher predictive accuracy with more reliable information (214, Breiman), which is beneficial because loosely accurate results can lead to unanswered questions and questioning the research. To Explain or to Predict? discusses the differences between explanatory modeling and predictive modeling and how combining the two can cause problems because of their differences. The distinction between the two is important because researchers assume that because a model explains well, it also predicts results well but that is not always true. Shmueli explains the differences, stating, “measurable data is not an accurate representation of their underlying constructs. The operationalization of theories… creates a disparity between the ability to explain at the conceptual level and the ability to generate predictions” (293, Shmueli). Because a model can explain the data and represent the research numerically and abstractly, does not mean the conclusions drawn from the explanatory models will represent the research with the most accuracy. Similar to Breiman, good models and measurable data do not mean that they create the best predictions or the best results. Both articles challenge the idea of using complex language and models for better predictions. Breiman suggests that simpler models are more reliable and Shmueli agrees that “blending simpler models [provides] more accurate predictions” (302, Shmueli). Both articles reject the idea of over explaining concepts and using complex models for the sake of originality or sophistication. They also encourage other researchers to think more about the goals of their research and how their models and predictions fit with their research, instead of trying to have their research match the models. However, there are differences between the articles; Shmueli focuses on study design and how explanations and predictions are not related to understanding, while Breiman centers his article on the overuse of data models. Shmueli discusses why different goals matter for current and future research, whereas Breiman suggests that research practices should change and embrace algorithmic models as a reliable method of data visualization. Even though each author takes a different approach to predictions and data, they both criticize researchers who are stubborn with their approaches and who do not acknowledge future impacts of their studies.\nBreiman, Leo. 2001. “Statistical modeling: The two cultures (with comments and a rejoinder by the author)”. Statistical Science, 16(3), pp.199-231 Shmueli, Galit. 2010. “To explain or to predict?.” Statistical science 25, no. 3: 289-310"
  },
  {
    "objectID": "Breiman and Shmueli.html",
    "href": "Breiman and Shmueli.html",
    "title": "Breiman and Shmueli",
    "section": "",
    "text": "Comparing “Statistical Modeling: The Two Cultures” and “To Explain or to Predict?”\nStatistical Modeling: The Two Cultures tackled the issue of data modeling being the primary approach in the science field, but algorithmic models are often more reliable for predictions in larger data sets and handling modern problems. For instance, Breiman discusses problems in data modeling by explaining a residual analysis where a data set is limited to two or three variables. He mentions that a goodness-of-fit test “lacks power in more than a few dimensions.” (203, Breiman) and how an acceptable plot does not mean that it is necessarily a good plot to use for data. He also explains that researchers are not usually looking for if the models they use fit the data, but if the model is new, clever, and sets them apart. Algorithmic models, although simpler, provide a higher predictive accuracy with more reliable information (214, Breiman), which is beneficial because loosely accurate results can lead to unanswered questions and questioning the research.\nTo Explain or to Predict? discusses the differences between explanatory modeling and predictive modeling and how combining the two can cause problems because of their differences. The distinction between the two is important because researchers assume that because a model explains well, it also predicts results well but that is not always true. Shmueli explains the differences, stating, “measurable data is not an accurate representation of their underlying constructs. The operationalization of theories… creates a disparity between the ability to explain at the conceptual level and the ability to generate predictions” (293, Shmueli). Because a model can explain the data and represent the research numerically and abstractly, does not mean the conclusions drawn from the explanatory models will represent the research with the most accuracy.\nSimilar to Breiman, good models and measurable data do not mean that they create the best predictions or the best results. Both articles challenge the idea of using complex language and models for better predictions. Breiman suggests that simpler models are more reliable and Shmueli agrees that “blending simpler models [provides] more accurate predictions” (302, Shmueli). Both articles reject the idea of over explaining concepts and using complex models for the sake of originality or sophistication. They also encourage other researchers to think more about the goals of their research and how their models and predictions fit with their research, instead of trying to have their research match the models. However, there are differences between the articles; Shmueli focuses on study design and how explanations and predictions are not related to understanding, while Breiman centers his article on the overuse of data models. Shmueli discusses why different goals matter for current and future research, whereas Breiman suggests that research practices should change and embrace algorithmic models as a reliable method of data visualization. Even though each author takes a different approach to predictions and data, they both criticize researchers who are stubborn with their approaches and who do not acknowledge future impacts of their studies.\nBreiman, Leo. 2001. “Statistical modeling: The two cultures (with comments and a rejoinder by the author)”. Statistical Science, 16(3), pp.199-231 Shmueli, Galit. 2010. “To explain or to predict?.” Statistical science 25, no. 3: 289-310"
  }
]